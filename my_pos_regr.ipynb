{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1e9c9d-de24-4e17-8e07-7da5614edf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер X_scaled: (877, 2027)\n",
      "Размер y_actual_log: (877,)\n",
      "Размер таблицы данных: (877, 59)\n",
      "\n",
      "Минимум X_scaled: -167.81064000001635\n",
      "Максимум X_scaled: 23968.290999999932\n",
      "Среднее X_scaled: 4.599451910521244\n",
      "Дисперсия X_scaled: 12134.427864974188\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "X_scaled = np.load(\"X_scaled_v3.npy\")\n",
    "y_actual_log = np.load(\"y_actual_log_fixed.npy\")\n",
    "df = pd.read_csv(\"for_regr_with_descrip.csv\")\n",
    "\n",
    "\n",
    "print(f\"Размер X_scaled: {X_scaled.shape}\")\n",
    "print(f\"Размер y_actual_log: {y_actual_log.shape}\")\n",
    "print(f\"Размер таблицы данных: {df.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nМинимум X_scaled: {np.min(X_scaled)}\")\n",
    "print(f\"Максимум X_scaled: {np.max(X_scaled)}\")\n",
    "print(f\"Среднее X_scaled: {np.mean(X_scaled)}\")\n",
    "print(f\"Дисперсия X_scaled: {np.var(X_scaled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99bf02ee-0e54-49f2-ba25-7e72475f3dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Модель загружена.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "try:\n",
    "    model = pickle.load(open(\"xgb_model.pkl\", \"rb\")) \n",
    "except FileNotFoundError:\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.load_model(\"xgb_model_fixed.json\")  \n",
    "print(\"\\nМодель загружена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67da671f-a01a-49a2-ae86-cac42084a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Добавляем 1 недостающих признаков (заполняем нулями).\n",
      "Новый размер X_scaled: (877, 2028)\n",
      "\n",
      "Размер X_scaled после исправления: (877, 2028)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "expected_features = model.n_features_in_\n",
    "current_features = X_scaled.shape[1]\n",
    "\n",
    "if current_features < expected_features:\n",
    "    missing_features = expected_features - current_features\n",
    "    print(f\"\\nДобавляем {missing_features} недостающих признаков (заполняем нулями).\")\n",
    "    X_scaled = np.hstack([X_scaled, np.zeros((X_scaled.shape[0], missing_features))])\n",
    "    print(f\"Новый размер X_scaled: {X_scaled.shape}\")\n",
    "\n",
    "elif current_features > expected_features:\n",
    "    print(\"\\nОшибка! У нас больше признаков, чем ожидает модель!\")\n",
    "\n",
    "print(f\"\\nРазмер X_scaled после исправления: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51866cfe-8f22-4d93-b17f-e95bebfdda85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучаем XGBoost...\n",
      "\n",
      "RMSE на тесте: 0.1359\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_actual_log, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "print(\"\\nОбучаем XGBoost...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"\\nRMSE на тесте: {rmse:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbda26d1-98f1-49c2-aa9f-2b71193b1c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обученная модель сохранена: xgb_model_v3.json\n"
     ]
    }
   ],
   "source": [
    "model.save_model(\"xgb_model_v3.json\")\n",
    "print(\"\\nОбученная модель сохранена: xgb_model_v3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06254fa-298c-4b45-b2b9-1a8fc297c2e3",
   "metadata": {},
   "source": [
    "минмакс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0553e83-0f0d-4bca-992e-45e62f623148",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_features = model.n_features_in_\n",
    "current_features = X_scaled.shape[1]\n",
    "\n",
    "if current_features < expected_features:\n",
    "    missing_features = expected_features - current_features\n",
    "    print(f\"\\nДобавляем {missing_features} недостающих признаков (заполняем нулями).\")\n",
    "    X_scaled = np.hstack([X_scaled, np.zeros((X_scaled.shape[0], missing_features))])\n",
    "    print(f\"Новый размер X_scaled: {X_scaled.shape}\")\n",
    "\n",
    "elif current_features > expected_features:\n",
    "    print(\"\\nОшибка! У нас больше признаков, чем ожидает модель!\")\n",
    "\n",
    "print(f\"\\nРазмер X_scaled после исправления: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c3904-b0fd-49b9-b6ac-7973009e9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Загружаем подготовленные признаки (уже очищенные от ненужных колонок)\n",
    "X_combined = np.load(\"X_scaled_v3.npy\")  # Или используй свою переменную с признаками\n",
    "\n",
    "# Используем MinMaxScaler вместо StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled_alt = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Сохраняем новый вариант масштабированных данных\n",
    "np.save(\"X_scaled_minmax.npy\", X_scaled_alt)\n",
    "\n",
    "print(\"Файл 'X_scaled_minmax.npy' успешно создан!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b1c14-7e93-4f3a-b0c4-2a0d633dcf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_features = model.n_features_in_\n",
    "current_features = X_scaled_alt.shape[1]\n",
    "\n",
    "if current_features < expected_features:\n",
    "    missing_features = expected_features - current_features\n",
    "    print(f\"\\nДобавляем {missing_features} недостающих признаков (заполняем нулями).\")\n",
    "    X_scaled_alt = np.hstack([X_scaled_alt, np.zeros((X_scaled_alt.shape[0], missing_features))])\n",
    "    print(f\"Новый размер X_scaled: {X_scaled_alt.shape}\")\n",
    "\n",
    "elif current_features > expected_features:\n",
    "    print(\"\\nОшибка! У нас больше признаков, чем ожидает модель!\")\n",
    "\n",
    "print(f\"\\nРазмер X_scaled_alt после исправления: {X_scaled_alt.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55fcc37-d886-49c7-bca8-863b83f88403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Разделяем данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_alt, y_actual_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаём модель XGBoost\n",
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42)\n",
    "\n",
    "# Обучаем модель\n",
    "print(\"\\nОбучаем XGBoost...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания на тестовых данных\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оцениваем качество\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"\\nRMSE на тесте: {rmse:.4f}\")\n",
    "\n",
    "# Сохраняем модель\n",
    "model.save_model(\"xgb_model_fixed.json\")\n",
    "print(\"\\nОбученная модель сохранена: xgb_model_fixed.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9831b69e-289e-4c6e-8634-380c42cd40dc",
   "metadata": {},
   "source": [
    "90% XGBoost + 10% LightGBM-- переобучена\n",
    "MAE ансамбля: 0.0570\n",
    " MAE train: 0.0028\n",
    " MAE на test: 0.0570 Минимальное значение y_test: 1.4771212547196624\n",
    "Максимальное  y_test: 3.2920344359947364\n",
    "\n",
    "\n",
    "минмакс тоже положительно не влияет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acfd538-d06c-45d0-94d0-269e47c79f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Загружаем данные\n",
    "X_scaled = np.load(\"X_scaled_v3.npy\")  # Используем нормализованные данные\n",
    "y_actual_log = np.load(\"y_actual_log_fixed.npy\")  # Целевая переменная\n",
    "\n",
    "# Разделяем данные на train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_actual_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучаем XGBoost\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Обучаем LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=100, random_state=42)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✅ XGBoost и LightGBM обучены!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b493c-fced-4726-b640-3f3b109c38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем предсказания на тесте\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Ансамбль: 90% XGBoost + 10% LightGBM\n",
    "y_pred_ensemble = 0.9 * y_pred_xgb + 0.1 * y_pred_lgb\n",
    "\n",
    "# Оценка качества\n",
    "mae_ensemble = mean_absolute_error(10**y_test, 10**y_pred_ensemble)  # Возвращаем масштаб из логарифма\n",
    "print(f\"\\n MAE ансамбля: {mae_ensemble:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9976213-9839-40f1-b5c5-97c9365f34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Проверяем min/max предсказаний\n",
    "print(\"\\n  Минимальное y_pred_ensemble:\", np.min(y_pred_ensemble))\n",
    "print(\" Максимальное y_pred_ensemble:\", np.max(y_pred_ensemble))\n",
    "\n",
    "# Проверяем min/max настоящих значений\n",
    "print(\"\\n Минимальное y_actual:\", np.min(10**y_test))\n",
    "print(\" Максимальное y_actual:\", np.max(10**y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846b8657-33d7-490d-be5e-0cc0cea5524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем предсказания в ЛОГАРИФМЕ\n",
    "y_pred_log_xgb = xgb_model.predict(X_test)  \n",
    "y_pred_log_lgb = lgb_model.predict(X_test)  \n",
    "\n",
    "\n",
    "y_pred_log_ensemble = 0.9 * y_pred_log_xgb + 0.1 * y_pred_log_lgb\n",
    "\n",
    "mae_log_ensemble = mean_absolute_error(y_test, y_pred_log_ensemble)\n",
    "print(f\"\\n MAE ансамбля (log10, как в POSEIDON): {mae_log_ensemble:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768f3a7-ae19-4bad-9191-91b3ceba0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE на train\n",
    "y_pred_train_xgb = xgb_model.predict(X_train)\n",
    "y_pred_train_lgb = lgb_model.predict(X_train)\n",
    "y_pred_train_ensemble = 0.9 * y_pred_train_xgb + 0.1 * y_pred_train_lgb\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train_ensemble)\n",
    "print(f\" MAE (log10) на train: {mae_train:.4f}\")\n",
    "\n",
    "# MAE на test (уже есть, но пересчитаем)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_ensemble)\n",
    "print(f\" MAE (log10) на test: {mae_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2c1b1-ba80-4d8c-8a55-86d5431ed0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Минимальное значение y_test: {np.min(y_test)}\")\n",
    "print(f\"Максимальное значение y_test: {np.max(y_test)}\")\n",
    "print(f\"Уникальные значения в y_test: {np.unique(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf416d-ac0b-4505-86c2-ee20040184ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "errors = y_test - y_pred_ensemble\n",
    "plt.hist(errors, bins=30, color=\"blue\", alpha=0.7)\n",
    "plt.xlabel(\"Ошибка предсказания (log10)\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.title(\"Распределение ошибок предсказания\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5cb71-4bad-45a3-a23a-5c2f544eca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Минимум X_train: {np.min(X_train)}\")\n",
    "print(f\"Максимум X_train: {np.max(X_train)}\")\n",
    "print(f\"Среднее X_train: {np.mean(X_train)}\")\n",
    "print(f\"Дисперсия X_train: {np.var(X_train)}\")\n",
    "\n",
    "print(f\"Минимум y_train: {np.min(y_train)}\")\n",
    "print(f\"Максимум y_train: {np.max(y_train)}\")\n",
    "print(f\"Среднее y_train: {np.mean(y_train)}\")\n",
    "print(f\"Дисперсия y_train: {np.var(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe670b83-d139-4d8c-aa4b-af6d2f66efa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
